<html>
<font color="BLACK">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Blind Monaural Source Separation on Heart and Lung Sounds Based on Periodic-Coded Deep Autoencoder</title>
<link rel="stylesheet" type="text/css" href="./resources/stylesheet.css">
<link rel="shortcut icon" href="../../resources/logo.png">
</head>

<body bgcolor="WHITE">
<div>
<h1>Blind Monaural Source Separation on Heart and Lung Sounds Based on Periodic-Coded Deep Autoencoder</h1>

<p><b>Paper:</b> <a href="">TBE</a></p>
<p><b>Authors:</b> Kun-Hsi Tsai, Wei-Chien Wang,  Chui-Hsuan Cheng, Chan-Yen Tsai, Jou-Kou Wang, Tzu-Hao Lin, 
Shih-Hau Fang, Li-Chin Chen, Yu Tsao

</p>

<p><b>Abstract:</b>
Auscultation is the most efficient way to diagnose cardiovascular and respiratory diseases. To reach accurate diagnoses, a device must be able to recognize heart and lung sounds from various clini-cal situations. However, the recorded chest sounds are mixed by heart and lung sounds. Thus, effectively separating these two sounds is critical in pre-processing stage.  Recent advances in machine learning have progressed on monaural source separations, but most of the well-known techniques require paired mixed sounds and indi-vidual pure sounds for model training. As to the preparation of pure heart and lung sounds is extremely difficult, special designs must be considered to derive effective heart and lung sound separation tech-niques. In this study, we proposed a novel periodicity-coded deep auto-encoder (PC-DAE) approach to separate mixed heart-lung sounds in an unsupervised manner via the assumption of different periodicities between heart rate and respiration rate. The PC-DAE benefits from deep-learning-based models by extracting representa-tive features and considers the periodicity of heart and lung sounds to carry out the separation. We evaluated PC-DAE on two datasets. The first one includes sounds from the Student Auscultation Mani-kin (SAM), and the second is prepared by recording chest sounds in real-world conditions. Experimental results indicate that PC-DAE outperforms several well-known separation works in terms of standardized evaluation metrics. Moreover, waveforms and spec-trograms demonstrate the effectiveness of PC-DAE compared to existing approaches. It is also confirmed that by using the proposed PC-DAE as a pre-processing stage, the heart sound recognition ac-curacies can be notably boosted. The experimental results con-firmed the effectiveness of PC-DAE and its potential to be used in clinical applications.
</p>




<!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/HNzxOOB0Gbw" frameborder="0"
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->



<table>
<tbody>
<tr>
<th>The convolutional deep autoencoder (DAE(C)) architecture.
</th>
<th>Flowchart:
</th>
</tr>


<tr>
<td><img src="fig/DCAE.jpg" width="390"></td>
<td><img src="fig/PC_DCAE.jpg" width="390"></td>
</tr>
</tbody>
</table>


<h2>Modulation frequency analysis method comparision(DFT, Wavelets)</h2>
<li>We added the following description in the revised manuscript: 
Please also note that any particular time-frequency representation method can be used to perform MFA. The present study adopts the DFT as a representative method. Other time-frequency representation methods, such as CWT [29-31] and Hilbert–Huang transform [63-65], can be used. When using these methods, suitable basis functions or prior knowledge need to be carefully considered. In this study, we intend to focus our attention on DFT and will further explore other time-frequency representation methods in the future. 
</li>
<table>
<tbody>
<tr>
<th>Supplement Table 1
</th>
<th>Supplement Table 2
</th>
</tr>


<tr>
<td><img src="fig/cwt_H.JPG" width="360"></td>
<td><img src="fig/cwt_L.JPG" width="360"></td>
</tr>
</tbody>
</table>



</p>

<h3>Random audio samples from Student Auscultation Manikin (SAM) testing set</h3>
<p>Meaning of the columns in the table below:

<ol>
<li>The mix heart-lung sound input to the PC-DAE(C). It's generated by summing the heart sound with lung sound in direct SNR.</li>
<li>The clean audio, which is the ground truth.</li>
<li>The separated results(heart, lung sound) from the PC-DAE(C) with Wavelets MFA and PC-DAE(C) with DFT MFA.</li>
</ol>
<h3>Case1:</h3>
<table>
<thead>
<!--
<tr>
<th>Noisy audio input</th>
<th>Enhanced audio output</th>
<th>Reference audio for d-vector</th>
<th>Clean audio (ground truth)</th>
</tr>
-->
</thead>




<!--case1-->


<tbody>

<!--case1-->

<tr>
<th>Mix heart-lung sound</th>
<th>clean heart sound</th>
<th>clean lung sound</th>
</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_ny.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_c.wav" type="audio/wav"></audio>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_n.wav" type="audio/wav"></audio></td>
</td>
</tr>
<tr>
<td>
<p><img src="audio/case3/0_1_ny.JPG" width="240"></p></td>
<td>
<p><img src="audio/case3/0_1_c.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case3/0_1_n.JPG" width="240"</p></td>
</td>

</tr>
<tr>
<td>
<p><img src="audio/case3/0_1_ny_s.JPG" width="240"></p></td>
<td>
<p><img src="audio/case3/0_1_c_s.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case3/0_1_n_s.JPG" width="240"</p></td>
</td>

</tr>
<tr>
<th>Separated heart sound(PC(DFT))</th>
<th>Separated lung sound(PC(DFT))</th>
<th>Separated heart sound(PC(Wavelets))</th>
<th>Separated lung sound(PC(Wavelets))</th>

</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_H.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_L.wav" type="audio/wav"></audio></td>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_H_W.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_L_W.wav" type="audio/wav"></audio>
</td>

</tr>

<tr>
<td>
<p><img src="audio/case3/0_1_H.JPG" width="240"></p></td>
<td>
<p><img src="audio/case3/0_1_L.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case3/0_1_H_W.JPG" width="240"</p></td>
</td>
<td>
<p><img src="audio/case3/0_1_L_W.JPG" width="240"</p></td>
</td>
</tr>
<tr>
<td>
<p><img src="audio/case3/0_1_H_s.JPG" width="240"></p></td>
<td>
<p><img src="audio/case3/0_1_L_s.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case3/0_1_H_W_s.JPG" width="240"</p></td>
</td>
<td>
<p><img src="audio/case3/0_1_L_W_s.JPG" width="240"</p></td>
</td>
</tr>
<!--endcase1-->
</tbody></table>


<h3>Case2:</h3>
<table>
<tbody>
<!--case1-->

<tr>
<th>Mix heart-lung sound</th>
<th>clean heart sound</th>
<th>clean lung sound</th>
</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_ny.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_c.wav" type="audio/wav"></audio>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_n.wav" type="audio/wav"></audio></td>
</td>
</tr>

<tr>
<td>
<p><img src="audio/case1/4_1_ny.JPG" width="240"></p></td>
<td>
<p><img src="audio/case1/4_1_c.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case1/4_1_n.JPG" width="240"</p></td>
</td>

</tr>
<tr>

<td>
<p><img src="audio/case1/4_1_ny_s.JPG" width="240"></p></td>
<td>
<p><img src="audio/case1/4_1_c_s.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case1/4_1_n_s.JPG" width="240"</p></td>
</td>
</tr>
<tr>
<th>Separated heart sound(PC(DFT))</th>
<th>Separated lung sound(PC(DFT))</th>
<th>Separated heart sound(PC(Wavelets))</th>
<th>Separated lung sound(PC(Wavelets))</th>

</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_H.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_L.wav" type="audio/wav"></audio></td>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_H_W.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_L_W.wav" type="audio/wav"></audio>
</td>

</tr>
<tr>
<td>
<p><img src="audio/case1/4_1_H.JPG" width="240"></p></td>
<td>
<p><img src="audio/case1/4_1_L.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case1/4_1_H_W.JPG" width="240"</p></td>
</td>
<td>
<p><img src="audio/case1/4_1_L_W.JPG" width="240"</p></td>
</td>
</tr>
<tr>
<td>
<p><img src="audio/case1/4_1_H_s.JPG" width="240"></p></td>
<td>
<p><img src="audio/case1/4_1_L_s.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case1/4_1_H_W_s.JPG" width="240"</p></td>
</td>
<td>
<p><img src="audio/case1/4_1_L_W_s.JPG" width="240"</p></td>
</td>
</tr>
<!--endcase1-->

<!--case1-->
</tbody>


</table>

<h3>Case3:</h3>

<table>
<tbody>
<tr>
<th>Mix heart-lung sound</th>
<th>clean heart sound</th>
<th>clean lung sound</th>
</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_ny.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_c.wav" type="audio/wav"></audio>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_n.wav" type="audio/wav"></audio></td>
</td>
</tr>
<tr>
<td>
<p><img src="audio/case2/8_1_ny.JPG" width="240"></p></td>
<td>
<p><img src="audio/case2/8_1_c.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case2/8_1_n.JPG" width="240"</p></td>
</td>

</tr>
<tr>
<td>
<p><img src="audio/case2/8_1_ny_s.JPG" width="240"></p></td>
<td>
<p><img src="audio/case2/8_1_c_s.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case2/8_1_n_s.JPG" width="240"</p></td>
</td>

</tr>
<tr>
<th>Separated heart sound(PC(DFT))</th>
<th>Separated lung sound(PC(DFT))</th>
<th>Separated heart sound(PC(Wavelets))</th>
<th>Separated lung sound(PC(Wavelets))</th>

</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_H.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_L.wav" type="audio/wav"></audio></td>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_H_W.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_L_W.wav" type="audio/wav"></audio>
</td>

</tr>
<tr>
<td>
<p><img src="audio/case2/8_1_H.JPG" width="240"></p></td>
<td>
<p><img src="audio/case2/8_1_L.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case2/8_1_H_W.JPG" width="240"</p></td>
</td>
<td>
<p><img src="audio/case2/8_1_L_W.JPG" width="240"</p></td>
</td>
</tr>
<tr>
<td>
<p><img src="audio/case2/8_1_H_s.JPG" width="240"></p></td>
<td>
<p><img src="audio/case2/8_1_L_s.JPG" width="240"<p>
</td>
<td>
<p><img src="audio/case2/8_1_H_W_s.JPG" width="240"</p></td>
</td>
<td>
<p><img src="audio/case2/8_1_L_W_s.JPG" width="240"</p></td>
</td>
</tr>
<!--endcase2-->
</tbody>


</table>


<h2>Code</h2>


<li>
TBE
</li>


<h2>Dataset information</h2>


<li><a href="https://www.cardionics.com/product/learning-systems/sam-3g-student-auscultation-manikin-3rd-generation">Cardionics. "SAM® 3G — Student Auscultation Manikin</a></li>

<h2>Copyright</h2>
<li><a href="http://www.imediplus.com/">Imediplus</a></li>
<li><a href="https://bio-asplab.citi.sinica.edu.tw/">Bio-ASP LAB</a></li>
</div>
</body>
</font>
</html>
