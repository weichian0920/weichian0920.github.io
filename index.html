<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Blind Monaural Source Separation on Heart and Lung Sounds Based on Periodic-Coded Deep Autoencoder</title>
<link rel="stylesheet" type="text/css" href="./resources/stylesheet.css">
<link rel="shortcut icon" href="../../resources/logo.png">
</head>

<body>
<div>
<h1>Blind Monaural Source Separation on Heart and Lung Sounds Based on Periodic-Coded Deep Autoencoder</h1>

<p><b>Paper:</b> <a href="">TBE</a></p>
<p><b>Authors:</b> Kun-Hsi Tsai, Wei-Chien Wang,  Chui-Hsuan Cheng, Chan-Yen Tsai, Jou-Kou Wang, Tzu-Hao Lin, 
Shih-Hau Fang, Li-Chin Chen, Yu Tsao

</p>

<p><b>Abstract:</b>
Auscultation is the most efficient way to diagnose cardiovascular and respiratory diseases. To reach accurate diagnoses, a device must be able to recognize heart and lung sounds from various clini-cal situations. However, the recorded chest sounds are mixed by heart and lung sounds. Thus, effectively separating these two sounds is critical in pre-processing stage.  Recent advances in machine learning have progressed on monaural source separations, but most of the well-known techniques require paired mixed sounds and indi-vidual pure sounds for model training. As to the preparation of pure heart and lung sounds is extremely difficult, special designs must be considered to derive effective heart and lung sound separation tech-niques. In this study, we proposed a novel periodicity-coded deep auto-encoder (PC-DAE) approach to separate mixed heart-lung sounds in an unsupervised manner via the assumption of different periodicities between heart rate and respiration rate. The PC-DAE benefits from deep-learning-based models by extracting representa-tive features and considers the periodicity of heart and lung sounds to carry out the separation. We evaluated PC-DAE on two datasets. The first one includes sounds from the Student Auscultation Mani-kin (SAM), and the second is prepared by recording chest sounds in real-world conditions. Experimental results indicate that PC-DAE outperforms several well-known separation works in terms of standardized evaluation metrics. Moreover, waveforms and spec-trograms demonstrate the effectiveness of PC-DAE compared to existing approaches. It is also confirmed that by using the proposed PC-DAE as a pre-processing stage, the heart sound recognition ac-curacies can be notably boosted. The experimental results con-firmed the effectiveness of PC-DAE and its potential to be used in clinical applications.
</p>




<!-- <iframe width="560" height="315" src="https://www.youtube.com/embed/HNzxOOB0Gbw" frameborder="0"
allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->

<h2>Random audio samples from Student Auscultation Manikin (SAM) testing set</h2>


<p><b>The convolutional deep autoencoder (DAE(C)) architecture.</b></p>
<p><img src="fig/DCAE.jpg" width="360"></p>
<p><b>Flowchart:</b></p>
<p><img src="fig/PC_DCAE.jpg" width="360"></p>
<h3>Modulation frequency analysis method comparision(Wavelets, DFT)</h3>
<table>
<tbody>
<tr>
<th>Supplement Table 1
</th>
<th>Supplement Table 2
</th>
</tr>

<li>Evaluation results of separated heart sounds (Supplement Table 1) and lung sound(Supplement Table 2) generated by the proposed PC-DAE(C) with CWT and DFT (termed PC-DAE(C)-CWT and PC-DAE(C)-DFT, respectively) in terms of SDR, SIR, and SAR. Avg denotes the average scores over five SNR levels.
</li>

<tr>
<td><img src="fig/cwt_H.jpg" width="360"></td>
<td><img src="fig/cwt_L.jpg" width="360"></td>
</tr>
</tbody>
</table>
<p>Meaning of the columns in the table below:

<ol>
<li>The mix heart-lung sound input to the PC-DAE(C). It's generated by summing the heart sound with lung sound in direct SNR.</li>
<li>The clean audio, which is the ground truth.</li>
<li>The separated results(heart, lung sound) from the PC-DAE(C) with Wavelets MFA and PC-DAE(C) with DFT MFA.</li>
</ol>

</p>



<table>
<thead>
<!--
<tr>
<th>Noisy audio input</th>
<th>Enhanced audio output</th>
<th>Reference audio for d-vector</th>
<th>Clean audio (ground truth)</th>
</tr>
-->
</thead>
<br></br>



<!--case1-->


<tbody>

<!--case1-->

<tr>
<th>Case 1:Mix heart-lung sound(SNR=-6dB)</th>
<th>clean heart sound</th>
<th>clean lung sound</th>
</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_ny.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_c.wav" type="audio/wav"></audio>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_n.wav" type="audio/wav"></audio></td>
</td>
</tr>
<tr>
<th>Separated heart sound(PC(Wavelets))</th>
<th>Separated lung sound(PC(Wavelets))</th>
<th>Separated heart sound(PC(DFT))</th>
<th>Separated lung sound(PC(DFT))</th>
</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_H_W.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_L_W.wav" type="audio/wav"></audio>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_H.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case3/0_1_L.wav" type="audio/wav"></audio></td>
</td>
</tr>
<!--endcase1-->


<!--case1-->

<tr>
<th>Case 2:Mix heart-lung sound(SNR=-6dB)</th>
<th>clean heart sound</th>
<th>clean lung sound</th>
</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_ny.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_c.wav" type="audio/wav"></audio>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_n.wav" type="audio/wav"></audio></td>
</td>
</tr>
<tr>
<th>Separated heart sound(PC(Wavelets))</th>
<th>Separated lung sound(PC(Wavelets))</th>
<th>Separated heart sound(PC(DFT))</th>
<th>Separated lung sound(PC(DFT))</th>
</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_H_W.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_L_W.wav" type="audio/wav"></audio>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_H.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case1/4_1_L.wav" type="audio/wav"></audio></td>
</td>
</tr>
<!--endcase1-->

<!--case1-->


<tr>
<th>Case 3:Mix heart-lung sound(SNR=-6dB)</th>
<th>clean heart sound</th>
<th>clean lung sound</th>
</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_ny.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_c.wav" type="audio/wav"></audio>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_n.wav" type="audio/wav"></audio></td>
</td>
</tr>
<tr>
<th>Separated heart sound(PC(Wavelets))</th>
<th>Separated lung sound(PC(Wavelets))</th>
<th>Separated heart sound(PC(DFT))</th>
<th>Separated lung sound(PC(DFT))</th>
</tr>
<tr>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_H_W.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_L_W.wav" type="audio/wav"></audio>
</td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_H.wav" type="audio/wav"></audio></td>
<td><audio controls class="audio-player" preload="metadata">
<source src="audio/case2/8_1_L.wav" type="audio/wav"></audio></td>
</td>
</tr>
<!--endcase1-->
</tbody>


</table>


<h2>FAQ</h2>

<h3>Can you share your code?</h3>

<p>
TBE
</p>


<h2>Dataset information</h2>

<p>
Cardionics. "SAM® 3G — Student Auscultation Manikin." https://www.cardionics.com/product/learning-systems/sam-3g-student-auscultation-manikin-3rd-generation.
</p>


<h2>Media coverage</h2>
<li><a href="http://www.imediplus.com/">Imediplus</a></li>
<li><a href="https://bio-asplab.citi.sinica.edu.tw/">Bio-ASP LAB</a></li>
</div>
</body>

</html>
